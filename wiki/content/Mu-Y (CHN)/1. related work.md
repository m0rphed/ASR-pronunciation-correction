Goodness-of-pronunciation (GOP) - один из первых методов MDD на основе DNN, который опирается на выходные данные автоматического распознавателя речи (ASR) [1, 2, 23] для оценки фонетических ошибок.  В последнее время изучалось сквозное распознавание фонем [3, 4, 5, 8, 24], среди которых в [4] и [24] также исследовалась тонкая настройка Wav2vec 2.0. Предлагаемый нами метод отличается от них тем, что мы исследуем использование немаркированной речи для повышения производительности MDD. 


#### Псевдомаркировка речи 
В целом, эти методы можно разделить на оффлайн и онлайн PL по схеме генерации псевдометок. 

Оффлайн-методы PL используют отдельно обучаемую модель учителя для присвоения псевдометок немаркированным образцам. 

Затем на помеченных и псевдопомеченных образцах обучается модель ученика [25]. 

Эвристики фильтрации [20, 22] и итеративное обучение [21] оказались полезными для улучшения качества PL. 

С другой стороны, в онлайн-методах PL псевдометки генерируются "на лету" самой онлайн-моделью [19, 26, 27]. 

Мы используем метод PL из [19], но, в отличие от [19], сочетаем PL с точной настройкой Wav2vec 2.0, а в качестве целей используем фонемы.


#### Wav2Vec2
Wav2vec 2.0 состоит из слоев конволюционной нейронной сети (CNN) и трансформера (рис. 1 (a)). 

![[Pasted image 20241013065447.png]]

Рисунок 1. Трехэтапное обучение: мы расширяем традиционную схему предварительного обучения (a) + файнтюн (b) дополнительным этапом тонкой настройки с помощью MPL (c). Обучающие данные из разных доменов отмечены разными цветами. 


CNN работает как экстрактор признаков, который преобразует входную аудиоформу X в латентное представление Z. Перед подачей на слои трансформатора Z случайным образом 
маскируется определенной частью (отмечена серым цветом на рис. 1 (a)). Затем слои трансформатора контекстуализируют Z в C.

Немаскированное латентное представление Z далее дискретизируется на Q с помощью обучаемой кодовой книги. Учитывая контекстуализированный репрезентации ct на замаскированном временном шаге t, мы обозначаем дискретизированную репрезентацию для временного шага t как q+ , а q− для других замаскированных шагов. 

Во время предварительного обучения Wav2vec 2.0 обучается с помощью контрастирующей потери, которая направлена на то, чтобы отличить истинное базовое дискретизированное 
представление q+ для каждого замаскированного шага t от тех, которые находятся в других замаскированных позициях (q− ), на основе контекстуализированного представления ct. 

Полная потеря SSL, обозначаемая как  Lpre - взвешенная сумма контрастирующей потери и diversity loss кодовой книги.

После pre-training мы добавляем линейные слои на трансформерные и удаляем модуль дискретизации. Вся модель (где CNN слои заморожены) подвергается сквозному файн-тюну
на задаче распознавания фонем речи L2 с использованием коннекционистской временной 
классификации (CTC) потери [28] (рис. 1 (b)). 

Пусть X = (x1, x2, ..., xT ) обозначает входную звуковую форму, Y = (y1, y2, ..., yL) обозначает цели обучения, которые в нашей задаче MDD представляют собой помеченные человеком последовательности фонем (т. е. то, что на самом деле произносит диктор L2). CTC Loss у  Llabel на помеченных образцах может быть выражена как
![[Pasted image 20241013070403.png]]
где A = (a1, a2...aT) обозначает совместимое латентное выравнивание между X и Y,  β(Y ) обозначает множество всех таких совместимых выравниваний, а θ обозначает параметры модели. Мы применяем скоростное возмущение [29] для X, а также модифицированный 
SpecAugment для латентных представлений Z, как в [10] для дополнения данных.


#### Файнтюн с помощью псевдопометки импульса
В дополнение к этапу тонкой настройки, на котором используются только меченые образцы, мы рассматриваем возможность включения в тонкую настройку немеченых образцов из таргет домена (рис. 1 (c)). 

Формально, при наличии доступных помеченных образцов L2 речи DL (те же образцы, что и на рис. 1 (b)) и дополнительные немаркированные образцы речи DU , наша цель - постоянно обучать новую модель ξ на основе базовой модели θ, полученной на предыдущем этапе тонкой настройки, используя как DL , так и DU . Мы предлагаем использовать немаркированные образцы с помощью импульсной псевдомаркировки (MPL) [19]. В MPL 
автономная модель учителя φ используется для присвоения псевдометок немаркированным образцам, которые направляют обучение онлайн-ученика. модель ξ. 

Псевдометки Yˆ выводятся по модели учителя φ:
![[Pasted image 20241013074154.png]]
где мы используем argmax для обозначения жадного декодирования CTC. 

Отметим, что модель, обученная с помощью такой неконтролируемой SSL-задачи, может быть дополнительно настроена в задаче ASR с использованием текстовых транскрипций предварительно обученного аудио, если они доступны, для получения аудио-текстового супервидения [10].


Таблица 1: Показатели оценки MDD и PER на тестовом наборе L2-ARCTIC. Цифры до и после "/" означают процентное и абсолютное количество вхождений конкретного случая. P и R означают Precision и Recall, соответственно. Показатели PER, отмеченные звездочкой (∗ ), напрямую не сравнимы с нашими из-за различий в настройках (см. раздел 5.3).
![[Pasted image 20241013074341.png]]
#### Экспериментальный сетап
Для обучения нашей модели MDD используется L2-ARCTIC [30]. 
В нем представлены маркированные человеком воспринимаемые фонемы примерно для 15 % высказываний каждого диктора. 
Следуя [4, 5], мы помеченные образцы 6 дикторов использовали в качестве тестового набора, а помеченные образцы остальных дикторов - как помеченный обучающий набор. 

Немаркированные образцы оставшихся 18 дикторов используются в качестве немаркированного обучающего множества. 

Мы случайным образом разделили 10 % помеченного обучающего множества как 
набор для разработки. Статистические показатели разбиения данных приведены в табл. 2. Поскольку L2-ARCTIC использует искусственные маркеры sil для представления удалений и включений фонем, для построения целевых обучающих последовательностей 
фонем мы перемещаем искусственные маркеры sil, сохраняя маркеры sil, соответствующие истинным паузам и молчанию.

UTD-4Accents [31] - это собственный набор данных, состоящий из 4 английских акцентов: американский (родной), австралийский, испанский и индийский. Мы используем часть с индийским акцентом для открытого теста (см. раздел 5.4), который включает 112 дикторов 
(сбалансированных по полу и возрасту). В качестве материала использовалась речь из различных областей, включая общеупотребительную лексику, голосовой поиск и т. д.

Мы оцениваем PER между распознанными фонемами и обучающими целями, а также метрику MDD в соответствии с [4, 32]. 

Для случаев правильного произношения, когда воспринимаемые человеком фонемы 
совпадают с каноническими фонемами (т.е. фонемами, которые должен был произносить носитель L2), мы имеем случаи истинного принятия (TA) и ложного отклонения (FR), основанные на том, совпадают ли предсказания модели с каноническими и воспринимаемыми фонемами. 













---
Аналогично, для случаев неправильного произношения, 
когда воспринимаемые человеком фонемы не совпадают с 
каноническими фонемами, мы можем иметь случаи 
ложного принятия (FA) и ложного отклонения (TR). TR 
можно дополнительно разделить на правильный диагноз и 
ошибочный диагноз, в зависимости от того, совпадают ли 
вычисляется из TR, FR, FA: P = TR/(FR + TR); R =
TR/(FA + TR); F 1 = 2PR/(P + R).

предсказания модели с человеческими

 

оценками.

 

Точность

 

(P), запоминание (R) и F1 могут быть

Таблица 2: Разбиение данных L2-ARCTIC и 
статистика.

4.3. Детали реализации
Мы настраиваем гиперпараметры на наборе 
разработки. Лучшая модель (с точки зрения PER) на 
наборе разработки оценивается на тестовом наборе. Мы 
экспериментировали с двумя предварительно 
обученными моделями Hugging- Face [33] Wav2vec 2.0, 
wav2vec2-base и wav2vec2- base-960h. Обе модели имеют 
идентичную архитектуру сети базового размера и 
предварительно обучены с одинаковой целью SSL 
(раздел 3.1) на 960-часовом аудио LibriSpeech [34]. 
wav2vec2- base-960h после предварительного обучения 
была дополнительно настроена с помощью задачи ASR 
на LirbiSpeech, которая обучает явному сопоставлению 
аудио и текста по сравнению с wav2vec2-base. Мы 
используем отдельные оптимизаторы Адама для 
линейных слоев и слоев Wav2vec 2.0 с фиксированными 
скоростями обучения 3e - 4 и 1e - 5, соответственно. 
Градиентная кумуляция используется для получения 
эффективного размера партии в 32. Все эксперименты 
проводились в течение 50 эпох на одном графическом 
процессоре NVIDIA RTX 2080. Наша реализация основана 
на инструментарии SpeechBrain [35].
5. Результаты
5.1. Эффект псевдоразметки и предварительно 
обученных моделей
В табл. 1 мы используем wav2vec2-base и wav2vec2-base-
960h для обозначения ванильных базовых моделей 
тонкой настройки, основанных на соответствующих 
предварительно обученных SSL-моделях без 
использования немаркированных образцов (т. е. этап (b) 
на рис. 1). Во-первых, мы видим, что с помощью MPL и 
wav2vec2-base, и wav2vec2-base-960h получают 
значительное улучшение по сравнению с ванильной 
базовой линией тонкой настройки, с точки зрения оценки 
F1 (wav2vec2-base: 56.16 против 54,80; wav2vec2-base-
960h: 55,42 против 55,10) и PER (wav2vec2- base: 14,69 
против 15,52; wav2vec2-base-960h: 14,36 против 14,87). 
Это демонстрирует преимущество использования 
немаркированных образцов L2. Во-вторых, интересным 
является тот факт, что wav2vec2-base-960h дает больше 
ложных принятий, меньше ложных отклонений и меньше 
всех случаев отклонения, чем wav2vec2-base, что 
приводит к более высокой Preci- sion, но более низкой 
Recall. Это означает, что он более "толерантен" к судьям, 
отвергая меньше произношений L2. Одна из возможных 
причин заключается в том, что дополнительный 
аудиотекстовый контроль склоняет его к каноническим 
произношениям, что делает его "слишком устойчивым" к 
неправильным произношениям. Однако для задачи MDD 
это может б ы т ь нежелательно, поскольку мы ожидаем, 
что модель MDD будет точно отражать то, что на самом 
деле произносит носитель L2, а "чрезмерная 
устойчивость" может скрыть неправильное 
произношение. В отличие от этого, wav2vec2-base имеет 
более сбалансированные показатели Precision и Recall.

Рисунок 2: (a) Сравнение PER с показателем 
разборчивости речи человека. Корреляция Пирсона = -
0,84 (p < 10−5 ); (b) PER vs. Human Accent- edness Score. 
Корреляция Пирсона = -0,75 (p < 10−3 ).
5.2. Влияние механизма обновления импульса
Чтобы выяснить, насколько MPL превосходит 
статические методы PL, мы сравнили MPL с двумя 
базовыми методами PL: (1) одноразовый PL (scratch): 
псевдометки генерируются в автономном режиме 
моделью, настроенной только на помеченные образцы (т. 
е. этап (b) на рис.
1). Затем новая модель обучается с нуля, используя 
псевдометки и исходные помеченные образцы; (2) one-
shot PL (continual): то же самое, что и в вышеописанном 
методе, за исключением того, что новая модель 
инициализируется весами модели, прошедшей тонкую 
настройку. Поскольку в обоих базовых вариантах 
псевдометки фиксируются после генерации, мы называем 
их одноразовыми. В табл. 1 приведено сравнение MPL с 
двумя базовыми линиями на wav2vec2-base. Хотя обе 
базовые линии превосходят по точности настройки только 
для меченых образцов, более значительное улучшение 
дает MPL, демонстрируя преимущества динамических 
псевдометок. Производительность двух базовых линий 
сопоставима, но одноразовый PL (непрерывный) немного 
хуже. Это может быть вызвано чрезмерной подгонкой.
5.3. Сравнение с предыдущими работами
Наконец, мы сравниваем наши модели MDD с 
современными ведущими методами MDD. В [8] 
используется модель CTC-Attention с дополнением Anti- 
Phone. [4] также основана на точной настройке Wav2vec
2.0 моделей и достигает передовых показателей MDD. 
Они использовали модели Wav2vec 2.0 большого размера, 
предварительно обученные на более крупных 
аудиокорпорациях. Модели в [4] имеют более 300 М 
параметров, в то время как наши модели имеют около 90 
М параметров.2 Из таб. 1 видно, что модель [8] имеет 
более высокий показатель Recall, но гораздо более низкий 
Precision. Предложенная нами модель MPL превосходит 
[8] по общему показателю F1. По сравнению с [4], хотя 
предложенный нами метод не превосходит его, мы 
наблюдаем более высокий процент правильных диагнозов 
и более низкий процент ошибочных диагнозов в 
процентах и абсолютном числе случаев. Это означает, что 
наши методы способны обеспечить более точную 
обратную связь для диагностики произношения, что 
может помочь учащимся L2 более эффективно исправлять 
свои ошибки в произношении. Отметим, что показатель 
PER, приведенный в [4], не может быть напрямую 
сопоставим с нашим, поскольку они не обрабатывали 
целевые последовательности фонем, как это делаем мы 
(раздел 4.1).
5.4. Открытый тест: Оценка индийского акцента и 

разборчивости
Мы предполагаем, что правильная модель MDD должна

 

воспринимать произношения L2 так же, как и человек, и,

 

следовательно, должна существовать корреляция между

 

эффективностью распознавания фонем и

 

акцентированностью и понятностью речи L2,
2Из-за ограниченности вычислительных ресурсов мы не можем 
провести эксперимент.

т.е. более высокий показатель PER (большее количество 
неправильных произношений) соответствует более 
тяжелому акценту и меньшей разборчивости. Наша цель 
- исследовать существование таких отношений, которые 
проливают свет на применимость модели MDD для 
автоматической оценки интеллектуальности речи на L2.
Для этого мы проводим открытый тест нашей лучшей 
модели MDD (wav2vec2-base + MPL) на индийской 
акцентированной речи L2 из набора данных UTD-
4Accents. Мы вычисляем PER для каждого диктора 
между распознанными фонемами и каноническими 
фонемами, полученными с помощью модели "графема-
фонема".3 Затем мы выбираем 10 дикторов с самым 
высоким PER и 10 дикторов с самым низким PER, и 
случайным образом отбираем по 10 высказываний для 
каждого из 20 дикторов. 17 человек-слушателей 
оценивают акцентированность (шкала: 1-9, где 1 означает 
сильный акцент) и разборчивость (шкала: 0-100, где 0 
означает "не разборчиво") отобранных высказываний. 
Каждый диктор получает 30+ оценок от разных 
оценщиков. Затем мы объединяем оценки 
акцентированности и разборчивости по каждому 
диктору. Все оценщики - аспиранты Университета 
Северной Аризоны с опытом преподавания или 
исследования произношения на L2 более 2 лет. Для 
получения беспристрастных оценок оценщикам 
предъявляется только текст L2 au- dio, без транскрипции 
текста или другой информации.
Мы построили график отношений PER-Intelligibility и 
PER- Accentedness для каждого говорящего на рис. 2 (a) и 
(b) соответственно. На рис. 2 (a) показывает, что дикторы 
примерно сгруппированы в два кластера ((i) и (ii)). Это 
соответствует нашим ожиданиям: поскольку мы выбрали 
20 дикторов с самым высоким и самым низким PER, мы 
ожидаем, что эти дикторы также будут сгруппированы в 
группы более и менее разборчивых. Кроме того, 
показатели PER и оценки разборчивости речи человека 
имеют сильную отрицательную корреляцию, что 
означает, что более высокие показатели PER 
соответствуют менее разборчивой речи. Такая 
отрицательная корреляция наблюдается и на графике 

итеты на больших моделях, но предлагаемые нами методы являются общими
Оставим применение моделей большего размера для будущих исследований

PER-Accentedness (рис. 2 (b)). Интересно, что помимо 
двух вышеупомянутых кластеров, мы наблюдаем еще 
один кластер (iv). Говорящие в этом кластере находятся в 
кластере (ii) на рис. 2
(a). Это указывает на то, что для этих дикторов человек 
воспринимает относительно сильные акценты, но при 
этом они остаются вполне разборчивыми. Возможно, это 
связано с тем, что помимо фонетических ошибок, на 
акцентированность также сильно влияют просодические 
факторы, такие как интонация, лексическое ударение и т. 
д., которые могут быть не столь важны для разборчивости. 
Поскольку наша модель MDD обнаруживает только 
ошибки фонетического уровня, оценка акцентированности 
этих дикторов находится за пределами ее возможностей. В 
итоге, соответствие между распознаванием фонем в 
модели MDD и человеческим восприятием подтвердило 
нашу мотивацию использовать модель MDD в качестве 
компонента для автоматической оценки разборчивости 
речи L2.
6. Выводы и благодарности
Мы представили подход к использованию 
немаркированной речи L2 для повышения 
производительности MDD с помощью псевдомаркировки. 
Кроме того, мы сделали один шаг вперед к использованию 
модели MDD для ау-томатической оценки разборчивости 
и акцентированности речи L2. Проведя тест на 
прослушивание, мы показали, что эффективность 
распознавания модели MDD сильно коррелирует с 
восприятием человека. В будущем мы планируем 
включить в систему оценки разборчивости речи L2 
больше атрибутов речи, таких как лексическое ударение, 
темп речи. Данное исследование выполнено при 
поддержке NSF EAGER CISE Project 2140415, а также 
частично Техасского университета в Далласе в рамках 
программы Distinguished Univer- sity Chair in 
Telecommunications Engineering, которую возглавляет J. H. 
L. Hansen. Мы хотели бы поблагодарить экспертов из 
Университета Северной Аризоны за их участие в нашем 
тесте на прослушивание.