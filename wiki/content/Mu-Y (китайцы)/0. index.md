



Summary:
- берем Wav2Vec2 (или другую SSL модель)
- файнтюним на размеченном датасете + псевдоразмеченным
- авторазметка проводится ансамблем линейных моделей динамически
- алгоритм разметки необычный -  MPL - momentum pseudo-labeling генерирует псевдопометки динамически 
- тестировали разметку на UTD-4Accents - датасет, размеченный людьми



Подробное введение:

В данной работе мы используем неразмеченную речь L2 с помощью процедуры псевдоразметки (PL - pseudo-labeling) и расширяем подход к fine-tuning-у на основе предварительно обученных моделей самоконтроля (SSL). 

В частности, мы используем Wav2vec 2.0 в качестве SSL-модели и файнтюним ее, используя оригинальные образцы речи L2 с метками и созданные образцы речи L2 с псевдометками. 

Наши псевдомаркировки динамичны и создаются ансамблем линейных моделей "на лету", что обеспечивает устойчивость нашей модели к шуму псевдометок. 

Мы показываем, что тонкая настройка с использованием псевдолейблов позволяет сократить количество ошибок в фонемах на 5,35% и улучшить показатель MDD F1 на 2,48% по сравнению с базовым уровнем тонкой настройки только с использованием меченых образцов. 

Предложенный метод PL также превосходит традиционные офлайновые методы PL. 

По сравнению с современными системами MDD, наше решение MDD обеспечивает более точную и последовательную диагностику фонетических ошибок. 

Кроме того, мы проводим открытый тест на отдельном наборе данных UTD-4Accents, где результаты распознавания нашей системы показывают сильную корреляцию с человеческим восприятием, основанным на акцентированности и разборчивости.

Мы используем Wav2vec 2.0 [10] в качестве предварительно обученной SSL модели и 
расширяем схему "предварительное обучение + fine-tuning" одним дополнительным этапом файн-тюна, на котором в train включаются псевдомаркированные L2-высказывания. 

Мы предлагаем использовать недавно разработанный метод импульсной псевдомаркировки (MPL - momentum pseudo-labeling) [19]. 

В отличие от обычных PL-методов [20, 21, 22], MPL генерирует псевдопометки динамически и в режиме онлайн через обучение учителя и ученика: онлайн-модель ученика обучается с помощью псевдопометок, сгенерированных офлайн моделью учителя. Модель учителя поддерживает основанное на импульсе скользящее среднее значение весов онлайн-модели, Это делает онлайн-модель устойчивой к шуму псевдометок и стабилизирует обучение на 
немаркированных выборках. 

Мы показываем, что тонкая настройка с помощью MPL улучшает базовую модель с ванильной тонкой настройкой на 5,35 % по коэффициенту ошибок фонем (PER) и на 2,48 % по показателю MDD F1.

Кроме того, мы сделали один шаг вперед на пути к использованию модели MDD для автоматической оценки разборчивости и акцентированности речи L2. Мы 
проводим открытое тестирование нашей модели MDD на отдельном корпусе L2 английского языка с индийским акцентом. С помощью теста на аудирование мы показали, что эффективность распознавания фонем моделью MDD сильно коррелирует с оценками разборчивости и акцентированности речи на L2. Этот результат показывает соответствие между предсказаниями модели MDD и человеческим восприятием.