
Для обнаружения ошибок произношения необходимо сначала отделить разговорную речь от других факторов сигнала, а затем выявить неправильно произнесенные звуки речи. 

Разделить речь на множество факторов сложно, поскольку речь - это сложный сигнал. 

Она состоит из 
- просодии (F0, длительность, энергия), 
- тембра голоса,
- представления разговорного языка. 

Разговорный язык определяется звуками, воспринимаемыми людьми.  Звуки являются реализацией фонем - абстрактного представления человека о том, как произносить слово/предложение. 

Речь также может быть изменчивой из-за канала записи и эффектов окружающей среды, таких как шум и реверберация. 

Выявление ошибок произношения является очень сложной задачей, в том числе из-за ограниченного количества записей с неправильно произнесенной речью. 

==Чтобы решить эти проблемы, мы переформулируем задачу обнаружения ошибок произношения как задачу генерации синтетической речи.==

Пусть s - речевой сигнал, r - последовательность фонем, которые пытается произнести пользователь (каноническое произношение), а e - последовательность вероятностей неправильного произношения на уровне фонем или слов. 

Первоначальная задача обнаружения ошибок произношения определяется следующим образом:

${e \sim p(e|s,r)}$

где формулировка задачи как задачи генерации синтетической речи определяется следующим образом:

${e \sim p(s|e,r)}$

Вероятность ошибок произношения для всех слов в предложении может быть рассчитана с помощью правила Байеса:

${p(e|s,r) = \frac{p(e|r)p(s|e,r)}{p(s|r)}}$

Из уравнения видно, что нет необходимости напрямую изучать вероятность  ошибок произношения ${p(e|s,r)}$, поскольку вся сложность задачи теперь перенесена на изучение процесса порождения речи ${p(s|e,r)}$. Такая постановка задачи открывает путь к включению в модель дополнительных предварительных знаний:

1. Замена фонемы в слове при сохранении исходного речевого сигнала приводит к ошибке в произношении (метод P2P).
2. Изменение речевого сигнала при сохранении исходного произношения приводит к ошибке в произношении (метод T2S).
3. Существует множество вариантов неправильно произнесенной речи, которые отличаются по тембру голоса и просодическим аспектам речи (метод S2S).


${p(e|s,r) = \frac{p(e|r)p(s|e,r)}{p(s|r)}}$

Для решения уравнения мы используем выборку Марковской цепи Монте-Карло (MCMC) [63]. Таким образом, предварительные знания могут быть учтены путем генерации N обучающих примеров
{ei , si , ri} для i = 1..N с использованием методов
- P2P (предварительные знания 1), 
- T2S (предварительные знания 2), 
- S2S (предварительные знания 3). 

Учет предварительных знаний интуитивно соответствует увеличению объема обучающих данных, что способствует превзойти современные модели обнаружения ошибок произношения, как это было показано ранее. 

Уравнение 3 может быть оптимизировано с помощью стандартных методов оптимизации на основе градиента. В следующих подразделах мы подробно рассмотрим методы P2P-преобразования, T2S и S2S для генерации правильно и 
неправильно произнесенной речи.


## P2P

Для создания синтетической неправильно произнесенной речи достаточно начать с правильно произнесенной речи и изменить соответствующую последовательность фонем.  

Можно заметить, что вероятность неправильного произношения зависит от расхождения между речевым сигналом и соответствующим каноническим произношением. Это приводит к модели P2P-преобразования.

![[Pasted image 20241011112923.png]]

Пусть {e_noerr , s, r} - один обучающий пример, содержащий: 
- последовательность 0s, обозначающую правильно произнесенные фонемы, 
- речевой сигнал,
- последовательность фонем, представляющий каноническое произношение - r

Пусть r' - последовательность фонем c неправильным произношением, таким как замена, вставка и удаление фонем:
r '∼ p(r'|r)
тогда вероятность неправильного произношения для j-й фонемы определяется следующим образом:

![[Pasted image 20241011113607.png]]

Вероятность неправильного произношения может быть спроецирована с уровня фонем на уровне слов. Слово считается неправильно произнесенным, если хотя бы одна пара фонем в слове {r'j , rj} не совпадает. 

В конце этого процесса новый обучающий пример создается с искусственно внесенными ошибками произношения: {e_err, s, r'}. 

Обратите внимание, что речевой сигнал s в новом обучающем примере не отличается от исходного обучающего примера, и изменена только транскрипция фонем.

**Реализация**
Для создания синтетических ошибок произношения мы используем простой  подход, заключающийся в измненении фонетической транскрипции  соответствующего речевого аудио. Сначала мы выбираем эти высказывания из датасета человеческой речи. Затем для каждого высказывания мы заменяем фонемы случайными фонемами с заданной вероятностью.

## T2S

Метод T2S расширяет возможности P2P, позволяя создавать речевые сигналы, соответствующие синтетическим неправильным произношениям. 

![[Pasted image 20241011114258.png]]

Метод T2S для генерации неправильно произнесенной речи является обобщением метода P2P.

Одна из проблем метода P2P заключается в том, что он не может генерировать речевой сигнал для вновь созданной последовательность фонем r'. 

В результате ошибки в произношении будут преобладать в обучающих данных, содержащих новые последовательности фонем r'. 
Следовательно, эти ошибки можно бдует обнаружить только на основе канонического представления r', игнорируя информацию, содержащейся в речевом сигнале. Чтобы смягчить эту проблему, необходимо два обучающих примера для фонем r', один из которых представляет собой неправильно произнесенную речь: {eerr , s, r'}, а второй - для правильного произношения: {enoerr , s', r'}, где:
![[Pasted image 20241011114732.png]]


Поскольку теперь у нас есть речевой сигнал s, можно создать еще один обучающий пример: {e_err , s' , r}. В целом, метод T2S расширяет единственный обучающий пример правильной речи в четыре комбинации правильного и неправильного произношения:
![[Pasted image 20241011114852.png]]
![[Pasted image 20241011114858.png]]

**Реализация**
- Синтетическая речь генерируется с помощью Neural TTS, описанного Латорре и другими [64]. 
- Neural TTS состоит из двух модулей. 
- Модуль генерации контекста представляет собой нейронную сеть кодера-декодера, основанную на внимании, которая генерирует мело-спектрограмму из последовательности фонем. 
- Затем нейронный вокодер преобразует ее в речевой сигнал. Нейронный вокодер представляет собой нейронную сеть, по архитектуре похожую на Parallel Wavenet [65]. 
- Нейронный TTS обучается на речи одного носителя языка. Чтобы генерировать слова с различными лексическими моделями ударения, мы изменяем лексические маркеры ударения, связанные с гласными в фонетической транскрипции слова. 
## S2S

- Метод S2S предназначен для моделирования разнообразной природы речи, поскольку существует множество способов правильно произнести предложение. 
- Просодические аспекты речи, такие как высота тона, длительность и энергия, могут варьироваться. Аналогично, фонемы могут произноситься по-разному. 
- Чтобы имитировать человеческую речь, методы генерации речи должны допускать аналогичный уровень вариативности. Метод T2S, описанный в предыдущем разделе, всегда выдает один и тот же результат для одной и той же входной последовательности фонем. Метод S2S призван преодолеть это ограничение.
- S2S преобразует входной речевой сигнал s таким образом, чтобы изменить произносимые фонемы (замены, вставки и удаления фонем) с входных фонем r' на целевые фонемы r, сохраняя при этом другие аспекты речи, включая тембр голоса и просодия (уравнение 7 и рисунок 1c). 
![[Pasted image 20241011115445.png]] 
 
- Таким образом, сохраняется естественная изменчивость человеческой речи, что приводит к генерации множества вариантов неправильно произнесенной речи. Просодия будет отличаться в разных вариантах предложения одного и того же диктора, а одно и то же предложение, произнесенное многими дикторами, будет отличаться по тембру голоса.
![[Pasted image 20241011115555.png]]

- Аналогично методу T2S, метод S2S выводит четыре типа произносимой речи правильно и неправильно: {e_noerr , s, r}, {e_err , s, r'}, {e_noerr , s', r'} и {e_err , s', r}.

**Реализация**
- Синтетическая речь генерируется путем внесения неправильных 
произношений во входную речь, при этом сохраняется длительность фонем и тембр голоса. Архитектура модели S2S показана на рисунке 2. 
![[Pasted image 20241011120104.png]]
-  **Mel-spectrogram (s)** — Входная мел-спектрограмма.
- **Forced alignment** — Принудительное выравнивание. На основе входных данных выравниваются фонемы.
- **Phoneme durations** — Длительность фонем, определенная после выравнивания.
- **Phonemes (r)** — Исходные фонемы.
- **Phoneme-to-phoneme mapping** — Сопоставление фонем, где исходные фонемы (r) преобразуются в другие фонемы (r').
- **Phonemes (r')** — Преобразованные фонемы.
- **Encoder-decoder** — Модель энкодер-декодер, которая использует преобразованные фонемы и длительности для генерации новой мел-спектрограммы.
- **Mel-spectrogram (s')** — Новая мел-спектрограмма.
- **Universal Vocoder** — Универсальный вокодер, который преобразует мел-спектрограмму в речевой сигнал.
- **Raw speech signal** — Выходной речевой сигнал.

Дополнительно:

- **Speaker id** — Идентификатор говорящего, который может использоваться на этапе сопоставления фонем.


Мел-спектрограмма входного речевого сигнала s принудительно выравнивается с соответствующими каноническими фонемами r, чтобы получить длительность фонем. Идентификатор диктора должен быть предоставлен вместе с входной  речью, чтобы можно было сохранить голос диктора-источника. Ошибки произношения вносятся в канонические фонемы r' в соответствии с методом P2P,  описанным в разделе 3.1. Ошибочно произнесенные фонемы r вместе с длительностью фонем и 
диктором
'
id обрабатываются кодером-декодером, который генерирует mel-спектрограмму s .
кодер-декодер преобразует представление на уровне фонем в характеристики на 
уровне кадровРисунок 2. Архитектура модели S2S для генерации неправильно произносимой синтетической речи с 
сохранением просодии и тембра голоса входной речи. Черные прямоугольники представляют данные 
(тензоры), а оранжевые коробки - блоки обработки. Эта цветовая нотация используется во всех 
диаграммах моделей машинного обучения в статье.

и затем параллельно генерирует все кадры mel-спектрограммы. Мел-
спектрограмма преобразуется в аудиосигнал с помощью Universal Vocoder [66]. 
Без Universal Vocoder было бы невозможно сгенерировать необработанный 
аудиосигнал для сотен дикторов, включенных в корпус LibriTTS. Детали метода 
S2S представлены в работах Шаха и др [20] и Цзяо и др [66]. Основное отличие этих двух моделей от нашей модели S2S заключается в использовании отображения P2P для внесения ошибок в произношение.


## Реферат на тему Формирование неправильной речи

Генерация синтетической неправильно произнесенной речи и обнаружение 
ошибок произношения были представлены с вероятностной точки зрения правила 
Байеса. С помощью этой формулировки мы можем лучше понять взаимосвязь 
между методами P2P, T2S и S2S и увидеть, что метод S2S обобщает два более 
простых метода. Следуя этой логике, мы можем утверждать, что использование 
правила Байеса дает нам хорошую математическую основу для потенциального 
дальнейшего обобщения метода S2S, например, путем добавления языковой 
переменной в модель для поддержки обнаружения многоязычных ошибок 
произношения. Существует еще одно преимущество моделирования 
обнаружения ошибок произношения с вероятностной точки зрения - оно 
открывает путь к совместному обучению моделей генерации неправильной речи 
и обнаружения ошибок произношения. В настоящей работе мы обучаем 
отдельные модели машинного обучения для обеих задач, но должно быть 
возможно обучать обе модели совместно, используя рамки вариативного вывода 
[67] вместо MCMC д л я вывода вероятности неправильного произношения в 
уравнении 3.